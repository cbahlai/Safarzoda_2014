abundance.model500<-glm(abundance~managed+fldiv_11+flarea_11, family=poisson, offset=N, data=complete.set, na.action="na.fail")
#check for spatial autocorrelation in residuals of best model
#Mantel test for spatial autocorrelation for each data set
#ade4 manual http://cran.r-project.org/web/packages/ade4/ade4.pdf
library(ade4)
site.dist<-dist(cbind(site.attributes$Long, site.attributes$Lat))
pred.dist<-dist(residuals(abundance.model500))
mantel.rtest(site.dist, pred.dist, nrepet =9999)
#No spatial autocorrelation in residuals!
############################################################
#next, let's model Simpson diversity of bees. We'll assume normal error structure for diversity.
#otherwise, use identical approach to abundance models, starting with insite attributes
simp.model<-glm(complete.set$simp~complete.set$managed+.,data=insite.attributes, na.action="na.fail")
dredge(simp.model, extra="R^2")
summary(model.avg(dredge(simp.model)))
#same thing at 500
simp.model500<-glm(complete.set$simp~complete.set$managed+.+complete.set$imp500, data=insite.attributes, na.action="na.fail")
dredge(simp.model500, extra="R^2")
summary(model.avg(dredge(simp.model500)))
#and again at 1000
simp.model1000<-glm(complete.set$simp~complete.set$managed+.+complete.set$imp1000, data=insite.attributes, na.action="na.fail")
dredge(simp.model1000, extra="R^2")
summary(model.avg(dredge(simp.model1000)))
#null model is best model for simpson diversity- okay, good to know
##########################################################
#next- rarefied richness. We'll assume normal error structure for rarefied richness.
#Use identical approach to diversity models, starting with insite attributes
srare.model<-glm(complete.set$Srare~complete.set$managed+.,data=insite.attributes, na.action="na.fail")
dredge(srare.model, extra="R^2")
summary(model.avg(dredge(srare.model)))
#at 500
srare.model500<-glm(complete.set$Srare~complete.set$managed+.+complete.set$imp500, data=insite.attributes, na.action="na.fail")
dredge(srare.model500, extra="R^2")
summary(model.avg(dredge(srare.model500)))
#and again at 1000
srare.model1000<-glm(complete.set$Srare~complete.set$managed+.+complete.set$imp1000, data=insite.attributes, na.action="na.fail")
dredge(srare.model1000, extra="R^2")
summary(model.avg(dredge(srare.model1000)))
#Richness is best explained by landscape factors at 500
#best model for rarefied richness is
srare.model500<-glm(Srare~imp500, data=complete.set, na.action="na.fail")
# Again, check for spatial autocorrelation in residuals of best model
pred.dist<-dist(residuals(srare.model500))
mantel.rtest(site.dist, pred.dist, nrepet =9999)
#No spatial autocorrelation in residuals!
##########################################################
#next- NMDS1. We'll assume normal error structure for NMDS outputs.
#Use identical approach to diversity models, starting with insite attributes
NMDS1.model<-glm(complete.set$NMDS1~complete.set$managed+.,data=insite.attributes, na.action="na.fail")
dredge(NMDS1.model, extra="R^2")
summary(model.avg(dredge(NMDS1.model)))
#at 500
NMDS1.model500<-glm(complete.set$NMDS1~complete.set$managed+.+complete.set$imp500, data=insite.attributes, na.action="na.fail")
dredge(NMDS1.model500, extra="R^2")
summary(model.avg(dredge(NMDS1.model500)))
#and again at 1000
NMDS1.model1000<-glm(complete.set$NMDS1~complete.set$managed+.+complete.set$imp1000, data=insite.attributes, na.action="na.fail")
dredge(NMDS1.model1000, extra="R^2")
summary(model.avg(dredge(NMDS1.model1000)))
#null model is best model for NMDS1- also good to know
##########################################################
#next- NMDS2. We'll assume normal error structure for NMDS outputs.
#Use identical approach to diversity models, starting with insite attributes
NMDS2.model<-glm(complete.set$NMDS2~complete.set$managed+.,data=insite.attributes, na.action="na.fail")
dredge(NMDS2.model, extra="R^2")
summary(model.avg(dredge(NMDS2.model)))
#at 500
NMDS2.model500<-glm(complete.set$NMDS2~complete.set$managed+.+complete.set$imp500, data=insite.attributes, na.action="na.fail")
dredge(NMDS2.model500, extra="R^2")
summary(model.avg(dredge(NMDS2.model500)))
#and again at 1000
NMDS2.model1000<-glm(complete.set$NMDS2~complete.set$managed+.+complete.set$imp1000, data=insite.attributes, na.action="na.fail")
dredge(NMDS2.model1000, extra="R^2")
summary(model.avg(dredge(NMDS2.model1000)))
# NMDS is best explained by landscape factors at 500+ hardscape
#best model for NMDS2 is
NMDS2.model500<-glm(NMDS2~imp500 +hardscape_11, data=complete.set, na.action="na.fail")
# Again, check for spatial autocorrelation in residuals of best model
pred.dist<-dist(residuals(NMDS2.model500))
mantel.rtest(site.dist, pred.dist, nrepet =9999)
#No spatial autocorrelation in residuals!
##############################################################
#
# Model selection exp 2
# Effect of garden and landscape, and bee communities
# on fruit set
#
##############################################################
#approach- look at landscape parameters, exactly as in exp 1
#then use bee community data as predictors
#for all models
############################
#landscape predictors
fruitset.model<-glm(complete.set$fruitset~complete.set$managed+.,data=insite.attributes, na.action="na.fail")
dredge(fruitset.model, extra="R^2")
summary(model.avg(dredge(fruitset.model)))
#at 500
fruitset.model500<-glm(complete.set$fruitset~complete.set$managed+.+complete.set$imp500, data=insite.attributes, na.action="na.fail")
dredge(fruitset.model500, extra="R^2")
summary(model.avg(dredge(fruitset.model500)))
# at 1000
fruitset.model1000<-glm(complete.set$fruitset~complete.set$managed+.+complete.set$imp1000, data=insite.attributes, na.action="na.fail")
dredge(fruitset.model1000, extra="R^2")
summary(model.avg(dredge(fruitset.model1000)))
#best site attributes model for fruit set
fruitset.model<-glm(fruitset~hardscape_11, data=complete.set, na.action="na.fail")
# Again, check for spatial autocorrelation in residuals of best model
pred.dist<-dist(residuals(fruitset.model))
mantel.rtest(site.dist, pred.dist, nrepet =9999)
#No spatial autocorrelation in residuals!
################################
#bee community predictors
#include hardscape from landscape model selection
#full model includes all bee community measures
fruitset.bee.model<-glm(fruitset~hardscape_11+abundance+simp+Srare+NMDS1+NMDS2,data=complete.set, na.action="na.fail")
dredge(fruitset.bee.model, extra="R^2")
summary(model.avg(dredge(fruitset.bee.model)))
# Best model just contains hardscape again, so no need to test for autocorrelation
#################################################################
#
#Multivariate analysis plotting communities by best factors from model
#selection, management, floral area
#
#
#
#################################################################
#NMDS of urban bee data to generate NMDS scores for community to use as response variables
#nmds performed on mean bees per transect rather than raw abundance
#### NOTE bee data has been zero adjusted (Clarke et al 2006) by adding a 'dummy' species with
#abundance of 1 for all sites
library(vegan)
ord<-metaMDS(urbanbees, autotransform=FALSE)
ord
hardscape<-site.attributes$hardscape_11
fldiv<-site.attributes$fldiv_11
flarea<-site.attributes$flarea_11
most_abund<-colSums(urbanbees)>35
plot(ord, disp='sites', type="n")
points(ord, display="sites", pch=19)
points(ord, display="species", select=which(most_abund==FALSE), pch=21, cex=1, col="red")
text(ord, display="species", select=which(most_abund==TRUE), cex=0.75, col="red")
#CCA to overlay environmental variables
# I used only the variables we used in model selection,
#because I can't see justifying two different
# decision rules for inclusion to reviwers
# but forest and water are significant when you put them in the ordfit CCA
ordfit<-envfit(ord~imp500+fldiv+hardscape+flarea, data=site.attributes, perm=1000)
plot(ordfit)
summary(ordfit)
ordfit
#simper analysis
mdsBin <- ifelse(complete.set$NMDS2 > 0, c("positive"), c("negative"))
sim<-simper(urbanbees, mdsBin)
summary(sim)
#################################################################
#
#Plots of best models for Abundance, Srare and NMDS2
#predicted vs observed
#
#
#
#################################################################
#First, call best models to get regression parameters
summary(abundance.model500)
summary(srare.model500)
summary(NMDS2.model500)
organic.factor = c()
for (i in 1:(length(complete.set$managed))) {
if (complete.set$managed[i]=="organic"){
organic.factor = c(organic.factor,0.33)
}
else{
organic.factor = c(organic.factor,0)
}
}
complete.set$abundance.pred<-exp(complete.set$N+1.33-0.0035*complete.set$fldiv_11+0.0044*complete.set$flarea_11+organic.factor)
complete.set$srare.pred<-14-0.045*complete.set$imp500
complete.set$NMDS2.pred<-0.92-0.013*complete.set$imp500-0.0074*complete.set$hardscape_11
library(ggplot2)
library(gridExtra)
abundance.plot<-ggplot(complete.set, aes(abundance.pred, abundance))+geom_point(size=4)+xlab(NULL)+ylab(NULL)+theme_bw()+ theme(legend.position="none")+ggtitle("Abundance")+coord_equal(ratio=1)+xlim(10, 150)+ylim(10, 150)
srare.plot<-ggplot(complete.set, aes(srare.pred, Srare))+geom_point(size=4)+xlab(NULL)+ylab(NULL)+theme_bw()+ theme(legend.position="none")+ggtitle("Richness")+coord_equal(ratio=1)+xlim(8, 16)+ylim(8, 16)
NMDS2.plot<-ggplot(complete.set, aes(NMDS2.pred, NMDS2))+geom_point(size=4)+xlab(NULL)+ylab(NULL)+theme_bw()+ theme(legend.position="none")+ggtitle("NMDS2")+coord_equal(ratio=1)+xlim(-1, 1)+ylim(-1, 1)+xlab("Predicted")
######################################
#
# Stack pred vs observed plots together
#
######################################
grid.arrange(arrangeGrob(abundance.plot, srare.plot, NMDS2.plot,ncol=1,widths=c(5/6,1/6), left="Observed"))
#
#     Analysis of Bennett 2011 Urban Bee data
#
#
#model selection experiment to determine what factors are
#most closely associated with bee community
#responses in Chicago urban gardens, 2011 and to determine
#association between bee community data and fruit
#set in these places
#
#bee community data will be used to generate response variables,
#site attributes will be used to create
#predictor variables for first experiment
#
#fruit set will be response variable, bee community and site
#attributes will be used as predictors in
#second model selection experiment
###################################################
#bring data in
#when prompted, choose bee_captures.csv from dropbox/Rdata
urbanbees<-read.csv(file.choose(), header=TRUE, row.names=1)
#when prompted, choose site_attributes.csv from dropbox/Rdata
site.attributes<-read.csv(file.choose(), header=TRUE)
#note- urbanbees includes dummy variable with 1 for all observations
#to zero-adjust dataset (Clarke et al 2006)
#create a dataset where all variables can be housed together with outputs from diversity analyses
complete.set<-site.attributes
####################################################
#    Step 1
#
# use community compostion data to generate community statistics
# to use as response variables in model selection
# vegan manual http://cran.r-project.org/web/packages/vegan/vegan.pdf
#
####################################################
library(vegan)
#raw diversity and richness by site
complete.set$H<-diversity(urbanbees)
complete.set$simp<-diversity(urbanbees, "simpson")
complete.set$S<-specnumber(urbanbees)
#rarified richness
raremax <- min(rowSums(urbanbees))
complete.set$Srare <- rarefy(urbanbees, raremax)
#also compute total bee abundance per site, minus dummy
complete.set$abundance<-rowSums(urbanbees)-1
#NMDS of urban bee data to generate NMDS scores for community to use as response variables
#nmds performed on mean bees per transect rather than raw abundance
#### NOTE bee data has been zero adjusted (Clarke et al 2006) by adding a 'dummy' species with
#abundance of 1 for all sites
ord<-metaMDS(urbanbees, autotransform=FALSE)
#we can play around with this and see how management, env trend with the NMDS scores.
#see http://cran.r-project.org/web/packages/vegan/vignettes/intro-vegan.pdf
ord
plot(ord, disp='sites')
#extract mds scores
ordscores<-scores(ord)
complete.set$NMDS1<-ordscores[,"NMDS1"]
grid.arrange(arrangeGrob(abundance.plot, srare.plot, NMDS2.plot,ncol=1,widths=c(5/6,1/6), left="Observed"))
View(complete.set)
View(complete.set)
View(enemies)
View(enemies)
View(insite.attributes)
View(insite.attributes)
View(urbanbees)
View(urbanbees)
######################################################
# Code for analysis performed in "Regime shifts in Harmonia"
# by Bahlai, van der Werf and Landis
######################################################
#read in raw data
datahaxyweeklyunculled<-read.csv(file="C:/Rdata/harmoniaweekly.csv", header=TRUE, na.strings="")
#####################################
#     variables and descriptions
# Data has five columns
#
# Year	- year sample was taken
# Ordinal_date- day of year sample was taken
# Captures- Total number of Harmonia axyridis observed
# Traps	- Total number of traps reporting on that sampling date
# Per_trap- Average number of Harmonia per trap
######################################
library(reshape)
#create dataset culled to a standard sampling date
cullpoint=241
datahaxyweekly<-datahaxyweeklyunculled[which(datahaxyweeklyunculled$Ordinal_date<cullpoint),]
#reshape the weekly observations to provide yearly total captures and traps
datahaxymelt<-melt(datahaxyweekly, id=1:2)
datahaxyraw<-cast(datahaxymelt, Year~variable, sum)
#compute Nt and Nt+1 in ladybeetles per trap based on yearly totals
datahaxyraw$Nt<-datahaxyraw$Captures/datahaxyraw$Traps
Nt1 = c()
for (i in 1:(length(datahaxyraw$Nt)-1)) {
Nt1 = c(Nt1,datahaxyraw$Nt[i+1])
}
#cut out last sampling year, because there is no Nt+1 for that year
datahaxy<-datahaxyraw[which(datahaxyraw$Year<max(datahaxyraw$Year)),]
#append Nt+1 column to dataset
datahaxy$Nt1<-Nt1
#run model selection on average captures per trap by year
library(minpack.lm)
#models with no breaks
logistic.model.1<-nlsLM(Nt1~ Nt*(1+r*(1- Nt/k)), start=list(r=1.5, k=0.5), data=datahaxy)
ricker.model.1<-nlsLM(Nt1~ Nt*exp(r*(1- Nt/k)), start=list(r=1.5, k=0.5), data=datahaxy)
cat("AIC for Logistic model with no breaks is ", AIC(logistic.model.1),  "\n")
cat("AIC for Ricker model with no breaks is ", AIC(ricker.model.1),  "\n")
summary(logistic.model.1)
summary(ricker.model.1)
#models with one break
#prevent data subsetting of <3 years from start of study
Break1=min(datahaxy$Year)+3
#set an arbitrarily high AIC to start comparing model AIcs to and best break point variables
logisticaicbest=2000
rickeraicbest=2000
Break1best.l=0
Break2best.l=0
Break1best.r=0
Break2best.r=0
#while loop to move break point one unit at a time
while (Break1< (max(datahaxy$Year))) {
#subset data at Break1
part1<-datahaxy[which(datahaxy$Year<Break1),]
part2<-datahaxy[which(datahaxy$Year>(Break1-1)),]
#if statement to discount data subsets with 3 or fewer observations
if(nrow(part1)>3 & nrow(part2)>3){
#run models on two subsets
logistic.model.1<-nlsLM(Nt1~ Nt*(1+r*(1- Nt/k)), start=list(r=1.5, k=0.5), data=part1)
ricker.model.1<-nlsLM(Nt1~ Nt*exp(r*(1- Nt/k)), start=list(r=1.5, k=0.5), data=part1)
logistic.model.2<-nlsLM(Nt1~ Nt*(1+r*(1- Nt/k)), start=list(r=1.5, k=0.5), data=part2)
ricker.model.2<-nlsLM(Nt1~ Nt*exp(r*(1- Nt/k)), start=list(r=1.5, k=0.5), data=part2)
#output combined AIC for each model type, noting the maximum year in the data subset
combAIC.log<-AIC(logistic.model.1)+AIC(logistic.model.2)
cat("AIC for Logistic model with 1 break at ", max(part1$Year), " is ", combAIC.log,", # data points:", nrow(part1), " , ", nrow(part2),  "\n")
combAIC.rick<-AIC(ricker.model.1)+AIC(ricker.model.2)
cat("AIC for Ricker model with 1 break at ", max(part1$Year), " is ", combAIC.rick,", # data points:", nrow(part1), " , ", nrow(part2),  "\n")
if (logisticaicbest>combAIC.log){
logisticaicbest=combAIC.log
Break1best.l=Break1
}
if (rickeraicbest>combAIC.rick){
rickeraicbest=combAIC.rick
Break1best.r=Break1
}
}
Break1<-Break1+1
}
#compute model parameters for best models with one break
#best logistic model with one break
######################################################
# Code for figures generated in "Regime shifts in Harmonia"
# by Bahlai, van der Werf and Landis
######################################################
#first, Harmonia population data
#pre-process data as it was used in analysis
#read in raw data
datahaxyweeklyunculled<-read.csv(file="C:/Rdata/harmoniaweekly.csv", header=TRUE, na.strings="")
#####################################
#     variables and descriptions
# Data has five columns
#
# Year	- year sample was taken
# Ordinal_date- day of year sample was taken
# Captures- Total number of Harmonia axyridis observed
# Traps	- Total number of traps reporting on that sampling date
# Per_trap- Average number of Harmonia per trap
######################################
library(reshape)
library(ggplot2)
library(gridExtra)
# for graphics, we will use the color palette GrandBudapest
# from Karthik Ram's wesanderson package
library(wesanderson)
#create dataset culled to a standard sampling date
cullpoint=241
datahaxyweekly<-datahaxyweeklyunculled[which(datahaxyweeklyunculled$Ordinal_date<cullpoint),]
#reshape the weekly observations to provide yearly total captures and traps
datahaxymelt<-melt(datahaxyweekly, id=1:2)
datahaxyraw<-cast(datahaxymelt, Year~variable, sum)
#compute Nt and Nt+1 in ladybeetles per trap based on yearly totals
datahaxyraw$Nt<-datahaxyraw$Captures/datahaxyraw$Traps
Nt1 = c()
for (i in 1:(length(datahaxyraw$Nt)-1)) {
Nt1 = c(Nt1,datahaxyraw$Nt[i+1])
}
#assign sampling year a phase, based on output of model selection
phase = c()
for (i in 1:(length(datahaxyraw$Year))) {
if(datahaxyraw$Year[i]<2001){
phase = c(phase, "A")
}
else if (datahaxyraw$Year[i]>2000& datahaxyraw$Year[i]<2006){
phase = c(phase, "B")
}
else {
phase = c(phase, "C")
}
}
datahaxyraw$phase<-phase
#phases for the lines that are to join time series points
phasea = c()
for (i in 1:(length(datahaxyraw$Year))) {
if(datahaxyraw$Year[i]<2001.1){
phasea = c(phasea, "A")
}
else if (datahaxyraw$Year[i]>2000& datahaxyraw$Year[i]<2006.1){
phasea = c(phasea, "B")
}
else if (datahaxyraw$Year[i]>2005.9){
phasea = c(phasea, "C")
}
}
datahaxyraw$phasea<-phasea
#cut out last sampling year, because there is no Nt+1 for that year
datahaxy<-datahaxyraw[which(datahaxyraw$Year<max(datahaxyraw$Year)),]
#append Nt+1 column to dataset
datahaxy$Nt1<-Nt1
######################################
#
# Generate time series figure
#
######################################
pal<-wes.palette(3, "GrandBudapest")
harmonia.timeseries<-ggplot(datahaxyraw, aes(Year, Nt, colour=phase, cex=1))+geom_point(size=4)+scale_color_manual(values = pal)+geom_line(data=datahaxyraw, aes(x=Year, y=Nt, group=phasea), size=1)+geom_line(size=1)+xlab("Year")+ylab("Average captures per trap")+theme_bw()+coord_equal(ratio=8)+geom_vline(xintercept=c(2000.9, 2005.9), colour="blue", linetype="longdash")+ theme(legend.key = element_blank())
harmonia.timeseries
######################################
#
# Generate Ricker model figure
#
######################################
phase.a<-function(x){x*exp(1.28*(1- x/0.33))}
phase.b<-function(x){x*exp(2.17*(1- x/0.47))}
phase.c<-function(x){x*exp(1.54*(1- x/0.30))}
phase.ac<-function(x){x*exp(1.47*(1- x/0.31))}
harmonia.ricker<-ggplot(datahaxy, aes(Nt, Nt1, colour=phase))+geom_point(size=4)+scale_color_manual(values = wes.palette(3, "GrandBudapest"))+xlab("N(t)")+ylab("N(t+1)")+theme_bw()+ theme(legend.key = element_blank())+stat_function(fun=phase.a, colour=pal[1], size=1)+stat_function(fun=phase.b, colour=pal[2], size=1)+stat_function(fun=phase.c, colour=pal[3], size=1)+stat_function(fun=phase.ac, colour="black", size=1, linetype="longdash")+coord_equal(ratio=1)
harmonia.ricker
######################################
#
# Pesticide by state data
#
######################################
#read in raw data
pesticide<-read.csv(file="C:/Rdata/midwest_soybean_pesticide_use.csv", header=TRUE, na.strings="")
#####################################
#     variables and descriptions
# Data has five columns
#
# Year	- year sample was taken
# State	- US state, where
#		IA= Iowa
#		IL= Illinois
#		MI= Michigan
#		WI= Wisconsin
# Compound- Insecticide active ingredient
# est_statewide_usage_kg- Statewide usage of this active
#		ingredient in soybean, as estimated by
#		Stone et al of the United States Geological Survey
# soy_planted_ha- area of soybean planted in this state, as reported
#		by the United States Department of Agriculture
#		National Agricultural Statistics Service
#
######################################
pesticide$rate_ha<-pesticide$est_statewide_usage_kg/pesticide$soy_planted_ha
#remove states we were unable to get consistent scouting data for
pesticide<-pesticide[which(pesticide$State=="IA" | pesticide$State=="IL"| pesticide$State=="MI"| pesticide$State=="WI" ),]
#create data subsets for each active ingredient
cyhalo<-pesticide[which(pesticide$Compound=="CYHALOTHRINLAMBDA"),]
esfen<-pesticide[which(pesticide$Compound=="ESFENVALERATE"),]
imid<-pesticide[which(pesticide$Compound=="IMIDACLOPRID"),]
thiam<-pesticide[which(pesticide$Compound=="THIAMETHOXAM"),]
#choose colour and shape palettes
pal1<-c((wes.palette(5, "Zissou"))[c(1, 3, 5)],(wes.palette(4, "Rushmore"))[4])
shapepal<-c(15,17,19,8)
#create base figure for legend
pesticide.timeseries.leg<-ggplot(cyhalo, aes(Year, rate_ha, colour=State,shape=State))+geom_point(size=4)+scale_color_manual(values = pal1)+geom_line(size=1)+xlab("Year")+ylab("kg active ingredient per hectare")+theme_bw()+ theme(legend.key = element_blank())+scale_shape_manual(values = shapepal)
#plots for each individual active ingredient
cyhalo.timeseries<-ggplot(cyhalo, aes(Year, rate_ha, colour=State, shape=State))+geom_point(size=4)+scale_color_manual(values = pal1)+geom_line(size=1)+xlab(NULL)+ylab(NULL)+theme_bw()+ theme(legend.position="none")+scale_shape_manual(values = shapepal)+geom_vline(xintercept=2005.5,colour="blue", linetype="longdash")+ggtitle("Cyhalothrin-lambda")
esfen.timeseries<-ggplot(esfen, aes(Year, rate_ha, colour=State, shape=State))+geom_point(size=4) +scale_color_manual(values = pal1)+geom_line(size=1)+xlab(NULL)+ylab(NULL)+theme_bw()+ theme(legend.position="none")+scale_shape_manual(values = shapepal)+geom_vline(xintercept=2005.5,colour="blue", linetype="longdash")+ggtitle("Esfenvalerate")
imid.timeseries<-ggplot(imid, aes(Year, rate_ha, colour=State, shape=State))+geom_point(size=4)+scale_color_manual(values = pal1)+geom_line(size=1)+xlab(NULL)+ylab(NULL)+theme_bw()+ theme(legend.position="none")+scale_shape_manual(values = shapepal)+geom_vline(xintercept=2005.5,colour="blue", linetype="longdash")+ggtitle("Imidacloprid")
thiam.timeseries<-ggplot(thiam, aes(Year, rate_ha, colour=State, shape=State))+geom_point(size=4)+scale_color_manual(values = pal1)+geom_line(size=1)+xlab("Year")+ylab(NULL)+theme_bw()+ theme(legend.position="none")+scale_shape_manual(values = shapepal)+geom_vline(xintercept=2005.5,colour="blue", linetype="longdash")+ggtitle("Thiamethoxam")
######################################
#
# Stack pesticide plots together
#
######################################
#pull legend out of plot
g_legend <- function(a.gplot){
tmp <- ggplot_gtable(ggplot_build(a.gplot))
leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
legend <- tmp$grobs[[leg]]
return(legend)}
leg<-g_legend(pesticide.timeseries.leg)
#stick plots together in a vertical stack with a legend on the right
grid.arrange(arrangeGrob(arrangeGrob(cyhalo.timeseries, esfen.timeseries, imid.timeseries, thiam.timeseries, ncol=1),leg,ncol=2,widths=c(5/6,1/6), left="kg active ingredient per hectare") )
######################################
#
# boxplot of pesticide use by aphid infestation level
#
######################################
aphids<-read.csv(file="C:/Rdata/soybean_aphid_ratings_midwest.csv", header=TRUE, na.strings="")
aphidmelt<-melt(aphids, id=1)
names(aphidmelt)[names(aphidmelt)=="variable"]<-"Year"
names(aphidmelt)[names(aphidmelt)=="State."]<-"State"
aphidmelt$Year<-gsub("X","", aphidmelt$Year)
aphidmelt<-aphidmelt[which(aphidmelt$Year<2012),]
#merge infestation data with pesticide use data
aphid.pest<-merge(pesticide, aphidmelt, by=c("Year","State"))
names(aphid.pest)[names(aphid.pest)=="value"]<-"infestation"
#cull out data from before 2005, when pesticides weren't widely used
aphid.pest<-aphid.pest[which(aphid.pest$Year>2004),]
aphid.pest$infestation<-factor(aphid.pest$infestation, levels=c("Low","Spotty","Moderate","High"))
aphid.cyhalo<-aphid.pest[which(aphid.pest$Compound=="CYHALOTHRINLAMBDA"),]
aphid.esfen<-aphid.pest[which(aphid.pest$Compound=="ESFENVALERATE"),]
aphid.imid<-aphid.pest[which(aphid.pest$Compound=="IMIDACLOPRID"),]
aphid.thiam<-aphid.pest[which(aphid.pest$Compound=="THIAMETHOXAM"),]
#create new colour palatte
pal2<-c(wes.palette(4, "Royal2"))
#create plots of estimated pesticide use by aphid infestation
cyhalo.boxplot<-ggplot(aphid.cyhalo, aes(x=infestation, y=rate_ha, fill=Compound))+geom_boxplot()+xlab(NULL)+ylab(NULL)+ggtitle("Cyhalothrin-lambda")+theme_bw()+scale_fill_manual(values=pal2[1])+stat_summary(fun.y=median, geom="line", aes(group=1), cex=1, linetype="longdash")+ theme(legend.position="none")
esfen.boxplot<-ggplot(aphid.esfen, aes(x=infestation, y=rate_ha, fill=Compound))+geom_boxplot()+xlab(NULL)+ylab(NULL)+ggtitle("Esfenvalerate")+theme_bw()+scale_fill_manual(values=pal2[2])+stat_summary(fun.y=median, geom="line", aes(group=1), cex=1, linetype="longdash")+ theme(legend.position="none")
imid.boxplot<-ggplot(aphid.imid, aes(x=infestation, y=rate_ha, fill=Compound))+geom_boxplot()+xlab(NULL)+ylab(NULL)+ggtitle("Imidacloprid")+theme_bw()+scale_fill_manual(values=pal2[3])+stat_summary(fun.y=median, geom="line", aes(group=1), cex=1, linetype="longdash")+ theme(legend.position="none")
thiam.boxplot<-ggplot(aphid.thiam, aes(x=infestation, y=rate_ha, fill=Compound))+geom_boxplot()+xlab(NULL)+ylab(NULL)+ggtitle("Thiamethoxam")+theme_bw()+scale_fill_manual(values=pal2[4]) +stat_summary(fun.y=median, geom="line", aes(group=1), cex=1, linetype="longdash")+ theme(legend.position="none")
#stack plots together
grid.arrange(arrangeGrob(cyhalo.boxplot, esfen.boxplot, imid.boxplot, thiam.boxplot, ncol=2), left="kg active ingredient per hectare", sub="Aphid infestation")
